{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To get access to the dataset:\n",
    "- If you already have the folder with the datasets, you might need to 'git pull' to ensure that it is updated\n",
    "> Else, clone repo using the command below <br>\n",
    "> \"git clone https://github.com/clemnyan/ENGS_108_Fall_2021.git\" <br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Problem 2: Introduction to TensorFlow**\n",
    "In this problem, we will start working in tensorflow to build deep learning systems starting with fully connected neural networks. We will focus on using the food image dataset we built in the last problem.\n",
    ">\n",
    "> **(a)** Using the food image dataset we built in the last problem (last week's assignment!), build a [tensorflow Data Dataset](https://www.tensorflow.org/api_docs/python/tf/data/Dataset) that is shuffled with a batch size of 10. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 978 files belonging to 9 classes.\n",
      "len(images): 32\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "only integer scalar arrays can be converted to a scalar index",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-b83700d26f90>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"uint8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"off\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__index__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1002\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1003\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__index__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__index__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__bool__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: only integer scalar arrays can be converted to a scalar index"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Code and explanation for 2a\n",
    "from PIL import Image\n",
    "import tqdm\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#tf.disable_v2_behavior() \n",
    "\n",
    "working_dir = \"datasets/\"\n",
    "\n",
    "folder = os.path.join(working_dir, 'ExampleFoodImageDataset')\n",
    "\n",
    "DATASET_SIZE = 978\n",
    "img_height = 32\n",
    "img_width = 32\n",
    "num_classes = 9\n",
    "\n",
    "all_data = tf.keras.utils.image_dataset_from_directory(\n",
    "  str(folder),\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  label_mode=\"categorical\"\n",
    ")\n",
    "\n",
    "class_names = all_data.class_names\n",
    "\n",
    "# Now we shuffle the dataset, and show the results for the first 9 elements\n",
    "# without the line below, the  code will return different set of the first 9 images\n",
    "#all_data = all_data.shuffle(10)\n",
    "\n",
    "\n",
    "def get_count(dataset1): \n",
    "    count=0\n",
    "    for images, _ in dataset1:\n",
    "      for i in images:\n",
    "        count = count+1\n",
    "    return count\n",
    "\n",
    "\n",
    "\n",
    "# plot assortment of positive and negative labels\n",
    "plt.figure(figsize=(10, 10))\n",
    "#get first batch of data\n",
    "for images, labels in all_data.take(1):\n",
    "  #get first 9 entries in batch\n",
    "  for i in range(9):\n",
    "    label = int(np.where(labels[i]>0)[0])\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "    plt.title(class_names[label])\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "\n",
    "# out of a total of 31 batches, take first 27 for training, 3 for validation, and 1 for test\n",
    "train_size = 26\n",
    "val_size = 4\n",
    "test_size = 1\n",
    "\n",
    "train_dataset = all_data.take(train_size)\n",
    "test_dataset = all_data.skip(train_size)\n",
    "val_dataset = test_dataset.skip(test_size)\n",
    "test_dataset = test_dataset.take(test_size)\n",
    "\n",
    "print(\"num total points: \" + str(get_count(all_data)))\n",
    "print(\"num train points: \" + str(get_count(train_dataset)))\n",
    "print(\"num validation points: \" + str(get_count(val_dataset)))\n",
    "print(\"num test points: \" + str(get_count(test_dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **(b)** Build a two layer fully connected neural network of any size with a ReLu activation function and a final softmax layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_x_batches = train_dataset.map(lambda x: x[0]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    /Users/paullintilhac/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py:853 train_function  *\n        return step_function(self, iterator)\n    /Users/paullintilhac/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py:842 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /Users/paullintilhac/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:1286 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /Users/paullintilhac/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2849 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /Users/paullintilhac/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:3632 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /Users/paullintilhac/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py:835 run_step  **\n        outputs = model.train_step(data)\n    /Users/paullintilhac/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py:788 train_step\n        loss = self.compiled_loss(\n    /Users/paullintilhac/opt/anaconda3/lib/python3.8/site-packages/keras/engine/compile_utils.py:201 __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    /Users/paullintilhac/opt/anaconda3/lib/python3.8/site-packages/keras/losses.py:141 __call__\n        losses = call_fn(y_true, y_pred)\n    /Users/paullintilhac/opt/anaconda3/lib/python3.8/site-packages/keras/losses.py:245 call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    /Users/paullintilhac/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    /Users/paullintilhac/opt/anaconda3/lib/python3.8/site-packages/keras/losses.py:1665 categorical_crossentropy\n        return backend.categorical_crossentropy(\n    /Users/paullintilhac/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    /Users/paullintilhac/opt/anaconda3/lib/python3.8/site-packages/keras/backend.py:4839 categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n    /Users/paullintilhac/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/tensor_shape.py:1161 assert_is_compatible_with\n        raise ValueError(\"Shapes %s and %s are incompatible\" % (self, other))\n\n    ValueError: Shapes (None, 9) and (None, 32, 32, 9) are incompatible\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-686373bb35ee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m               metrics=['accuracy'])\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 _r=1):\n\u001b[1;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    931\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    757\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_deleter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFunctionDeleter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lifted_initializer_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m     self._concrete_stateful_fn = (\n\u001b[0;32m--> 759\u001b[0;31m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    760\u001b[0m             *args, **kwds))\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3064\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3065\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3066\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3067\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3068\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3462\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3463\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3464\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3296\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3297\u001b[0m     graph_function = ConcreteFunction(\n\u001b[0;32m-> 3298\u001b[0;31m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[1;32m   3299\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3300\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1005\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1007\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1008\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1009\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    666\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 668\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    669\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    992\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    993\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 994\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    995\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /Users/paullintilhac/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py:853 train_function  *\n        return step_function(self, iterator)\n    /Users/paullintilhac/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py:842 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /Users/paullintilhac/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:1286 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /Users/paullintilhac/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2849 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /Users/paullintilhac/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:3632 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /Users/paullintilhac/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py:835 run_step  **\n        outputs = model.train_step(data)\n    /Users/paullintilhac/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py:788 train_step\n        loss = self.compiled_loss(\n    /Users/paullintilhac/opt/anaconda3/lib/python3.8/site-packages/keras/engine/compile_utils.py:201 __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    /Users/paullintilhac/opt/anaconda3/lib/python3.8/site-packages/keras/losses.py:141 __call__\n        losses = call_fn(y_true, y_pred)\n    /Users/paullintilhac/opt/anaconda3/lib/python3.8/site-packages/keras/losses.py:245 call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    /Users/paullintilhac/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    /Users/paullintilhac/opt/anaconda3/lib/python3.8/site-packages/keras/losses.py:1665 categorical_crossentropy\n        return backend.categorical_crossentropy(\n    /Users/paullintilhac/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    /Users/paullintilhac/opt/anaconda3/lib/python3.8/site-packages/keras/backend.py:4839 categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n    /Users/paullintilhac/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/tensor_shape.py:1161 assert_is_compatible_with\n        raise ValueError(\"Shapes %s and %s are incompatible\" % (self, other))\n\n    ValueError: Shapes (None, 9) and (None, 32, 32, 9) are incompatible\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "  # data_augmentation,\n",
    "  layers.Rescaling(1./255, input_shape=(img_height, img_width, 3)),\n",
    "  layers.Dense(128, activation='relu'),\n",
    "  layers.Dense(128, activation='relu'),\n",
    "  layers.Dense(9, activation = 'softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_dataset, epochs=10, verbose=1)\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Test the model after training\n",
    "#test_results = model.evaluate(X_test, Y_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num features: 2352\n"
     ]
    }
   ],
   "source": [
    "# Code and explanation\n",
    "# This code is following along with the tutorial described here: \n",
    "# https://towardsdatascience.com/multi-layer-perceptron-using-tensorflow-9f3e218a4809\n",
    "num_classes = 9\n",
    "num_features = data.shape[1]\n",
    "print(\"num features: \" + str(num_features))\n",
    "num_output = 9\n",
    "num_layers_0 = 512\n",
    "num_layers_1 = 256\n",
    "starter_learning_rate = 0.001\n",
    "regularizer_rate = 0.1\n",
    "# print(tf.__version__)\n",
    "# tf.compat.v1.enable_v2_behavior()\n",
    "# dataset = tf.data.Dataset.as_numpy(dataset)\n",
    "\n",
    "# Placeholders for the input data\n",
    "input_X = tf.placeholder('float32',shape =(None,num_features),name=\"input_X\")\n",
    "input_y = tf.placeholder('float32',shape = (None,num_classes),name='input_Y')\n",
    "## for dropout layer\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "## Weights initialized by random normal function with std_dev = 1/sqrt(number of input features)\n",
    "weights_0 = tf.Variable(tf.random_normal([num_features,num_layers_0], stddev=(1/tf.sqrt(float(num_features)))))\n",
    "bias_0 = tf.Variable(tf.random_normal([num_layers_0]))\n",
    "weights_1 = tf.Variable(tf.random_normal([num_layers_0,num_layers_1], stddev=(1/tf.sqrt(float(num_layers_0)))))\n",
    "bias_1 = tf.Variable(tf.random_normal([num_layers_1]))\n",
    "weights_2 = tf.Variable(tf.random_normal([num_layers_1,num_output], stddev=(1/tf.sqrt(float(num_layers_1)))))\n",
    "bias_2 = tf.Variable(tf.random_normal([num_output]))\n",
    "\n",
    "## Initializing weigths and biases\n",
    "hidden_output_0 = tf.nn.relu(tf.matmul(input_X,weights_0)+bias_0)\n",
    "hidden_output_0_0 = tf.nn.dropout(hidden_output_0, rate = 1- keep_prob)\n",
    "hidden_output_1 = tf.nn.relu(tf.matmul(hidden_output_0_0,weights_1)+bias_1)\n",
    "hidden_output_1_1 = tf.nn.dropout(hidden_output_1, rate = 1-keep_prob)\n",
    "predicted_y = tf.sigmoid(tf.matmul(hidden_output_1_1,weights_2) + bias_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code first defines placeholders for the input variable, which will be 2352=28*28*3 dimensional, and start off with 0 rows. The output variable will be 9-dimensional, with one output for each class in the dataset. The biases and weights are then initialized with random normal samples, with mean 0. For the weights, the standard deviation is weighted with the inverse of the square root of the number of features, which the bias starts off as a standard normal with variance 1. Finally, each output layer is defined in terms of its previous layer, and an activation function (with the initialized weights an biases defined in the previous step). \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **(c)** Compile your model with an appropriate loss function and optimizer. Briefly describe your choices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code and explanation \n",
    "\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=predicted_y,labels=input_y)) \\\n",
    "        + regularizer_rate*(tf.reduce_sum(tf.square(bias_0)) + tf.reduce_sum(tf.square(bias_1)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The loss being used is the cross-entropy loss, plus a regularization term that penalizes large bias terms. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **(d)** Train your model on the food image training dataset. And report your accuracy on the testing dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code and explanation\n",
    "s = tf.InteractiveSession()\n",
    "\n",
    "## Variable learning rate\n",
    "learning_rate = tf.train.exponential_decay(starter_learning_rate, 0, 5, 0.85, staircase=True)\n",
    "## Adam optimzer for finding the right weight\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate).minimize(loss,var_list=[weights_0,weights_1,weights_2,\n",
    "\n",
    "## Metrics definition\n",
    "correct_prediction = tf.equal(tf.argmax(y_train,1), tf.argmax(predicted_y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "                                                                          \n",
    "## Training parameters\n",
    "batch_size = 128\n",
    "epochs=14\n",
    "dropout_prob = 0.6\n",
    "training_accuracy = []\n",
    "training_loss = []\n",
    "testing_accuracy = []\n",
    "s.run(tf.global_variables_initializer())\n",
    "for epoch in range(epochs):    \n",
    "    arr = np.arange(X_train.shape[0])\n",
    "    np.random.shuffle(arr)\n",
    "    for index in range(0,X_train.shape[0],batch_size):\n",
    "        s.run(optimizer, {input_X: X_train[arr[index:index+batch_size]],\n",
    "                          input_y: y_train[arr[index:index+batch_size]],\n",
    "                        keep_prob:dropout_prob})\n",
    "    training_accuracy.append(s.run(accuracy, feed_dict= {input_X:X_train, \n",
    "                                                         input_y: y_train,keep_prob:1}))\n",
    "    training_loss.append(s.run(loss, {input_X: X_train, \n",
    "                                      input_y: y_train,keep_prob:1}))\n",
    "    \n",
    "    ## Evaluation of model\n",
    "    testing_accuracy.append(accuracy_score(y_test.argmax(1), \n",
    "                            s.run(predicted_y, {input_X: X_test,keep_prob:1}).argmax(1)))\n",
    "    print(\"Epoch:{0}, Train loss: {1:.2f} Train acc: {2:.3f}, Test acc:{3:.3f}\".format(epoch,\n",
    "                                                                    training_loss[epoch],\n",
    "                                                                    training_accuracy[epoch],\n",
    "                                                                   testing_accuracy[epoch]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **(e)** Now try to tune this network by varying the number of layers, units, activations and see if you can outperform the network in part (d). Does your best model perform better or worse than the SVM in problem 1?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code and explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **(BONUS)** We lost a lot of information when we resized the images in part (a). What would happen if we didn't resize the images and we built fit the neural network with all this other information? Try it out! *Hint: Runtime will be much longer, both to create the image dataset without resizing and to train the model, so you might have to get the code working and then just let it run.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code and explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **(BONUS)** Implement and explain other feature engineering (and data augmentation) techniques that we can perform to increase prediction accuracy? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code and explanation\n",
    "\n",
    "\n",
    "\n",
    "# data_augmentation = tf.keras.Sequential(\n",
    "#   [\n",
    "#     layers.RandomFlip(\"horizontal\",\n",
    "#                       input_shape=(img_height,\n",
    "#                                   img_width,\n",
    "#                                   3)),\n",
    "#     layers.RandomRotation(0.1),\n",
    "#     layers.RandomZoom(0.1),\n",
    "#   ]\n",
    "# )\n",
    "# shuffle with buffer size 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
